# Example environment configuration

### LLM configuration - configure multiple LLMs to allow for different analyses
#LLM_MODEL=openai/gpt-4o # passed in via config
LLM_KEY=sk-proj-...
OPENAI_LLM_KEY=sk-proj-...

ANTHROPIC_API_KEY=sk-...

# include keys for the models you want to use

# user settings
USER_NAME='John Doe'

### Temporal configuration
## local dev server
TEMPORAL_ADDRESS=localhost:7233
TEMPORAL_NAMESPACE=default
TEMPORAL_TASK_QUEUE=insurance-agent-task-queue
## Temporal Cloud
# TEMPORAL_ADDRESS=namespace.acct.tmprl.cloud:7233
# TEMPORAL_NAMESPACE=default
# TEMPORAL_TASK_QUEUE=repair-agent-task-queue

# Uncomment if using mTLS (not needed for local dev server)
# TEMPORAL_TLS_CERT='path/to/cert.pem'
# TEMPORAL_TLS_KEY='path/to/key.pem'

# Uncomment if using API key (not needed for local dev server)
# TEMPORAL_API_KEY=abcdef1234567890

QUIRKY_LEVEL=.10 # No matter what you set this to, this demo is quirky 10% of the time
